import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

df = pd.read_csv('../pitchers_data_with_opp_so.csv')


# Exibindo informa√ß√µes b√°sicas
print("=== INFORMA√á√ïES B√ÅSICAS ===")
print(f"Dimens√µes do dataset: {df.shape}")
print(f"\nPrimeiras 5 linhas:")
print(df.head())

print(f"\nInforma√ß√µes do dataset:")
print(df.info())

print(f"\nEstat√≠sticas descritivas:")
print(df.describe())

# =============================================================================
# C√âLULA 3: VERIFICA√á√ÉO DE QUALIDADE DOS DADOS
# =============================================================================

# Verificando se h√° valores nulos
print("=== VERIFICA√á√ÉO DE DADOS NULOS ===")
print(df.isnull().sum())

# Verificando valores √∫nicos por coluna
print(f"\n=== VALORES √öNICOS ===")
for col in df.columns:
    print(f"{col}: {df[col].nunique()} valores √∫nicos")

# Verificando se h√° valores duplicados
print(f"\nLinhas duplicadas: {df.duplicated().sum()}")


df = df[df['IP'] >= 1]

print(f"\nAp√≥s remover linhas com IP < 1, o dataset possui {df.shape[0]} linhas e {df.shape[1]} colunas.")

# =============================================================================
# AN√ÅLISE DE CORRELA√á√ÉO COM SO (STRIKEOUTS)
# =============================================================================

print("\n" + "="*60)
print("AN√ÅLISE DE CORRELA√á√ÉO COM SO (STRIKEOUTS)")
print("="*60)

# Selecionando apenas colunas num√©ricas para correla√ß√£o
numeric_columns = df.select_dtypes(include=[np.number]).columns
correlation_with_so = df[numeric_columns].corr()['SO'].sort_values(ascending=False)

print("\n=== CORRELA√á√ïES COM SO (ordenadas por magnitude) ===")
for feature, corr in correlation_with_so.items():
    if feature != 'SO':
        print(f"{feature:15} : {corr:8.4f}")

# Criando visualiza√ß√µes
plt.style.use('default')
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('An√°lise de Correla√ß√£o com Strikeouts (SO)', fontsize=16, fontweight='bold')

# 1. Heatmap de correla√ß√£o
correlation_matrix = df[numeric_columns].corr()
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, cbar_kws={"shrink": .8}, ax=axes[0,0])
axes[0,0].set_title('Matriz de Correla√ß√£o Completa')

# 2. Correla√ß√µes com SO em barras
so_correlations = correlation_with_so.drop('SO')
colors = ['red' if x < 0 else 'blue' for x in so_correlations.values]
axes[0,1].barh(so_correlations.index, so_correlations.values, color=colors, alpha=0.7)
axes[0,1].set_title('Correla√ß√µes com SO')
axes[0,1].set_xlabel('Coeficiente de Correla√ß√£o')
axes[0,1].axvline(x=0, color='black', linestyle='-', alpha=0.3)

# 3. Scatter plot das 3 features mais correlacionadas positivamente
top_positive = so_correlations.head(3)
for i, (feature, corr) in enumerate(top_positive.items()):
    axes[1,0].scatter(df[feature], df['SO'], alpha=0.6, label=f'{feature} (r={corr:.3f})')
axes[1,0].set_xlabel('Valor da Feature')
axes[1,0].set_ylabel('Strikeouts (SO)')
axes[1,0].set_title('Top 3 Features Positivamente Correlacionadas')
axes[1,0].legend()

# 4. Scatter plot das 3 features mais correlacionadas negativamente
top_negative = so_correlations.tail(3)
for i, (feature, corr) in enumerate(top_negative.items()):
    axes[1,1].scatter(df[feature], df['SO'], alpha=0.6, label=f'{feature} (r={corr:.3f})')
axes[1,1].set_xlabel('Valor da Feature')
axes[1,1].set_ylabel('Strikeouts (SO)')
axes[1,1].set_title('Top 3 Features Negativamente Correlacionadas')
axes[1,1].legend()

plt.tight_layout()
plt.savefig('../correlation_analysis_so.png', dpi=300, bbox_inches='tight')
plt.show()

# An√°lise estat√≠stica adicional
print("\n=== AN√ÅLISE ESTAT√çSTICA DETALHADA ===")
print(f"Correla√ß√£o mais forte positiva: {top_positive.index[0]} (r = {top_positive.iloc[0]:.4f})")
print(f"Correla√ß√£o mais forte negativa: {top_negative.index[-1]} (r = {top_negative.iloc[-1]:.4f})")

# Correla√ß√µes significativas (|r| > 0.3)
significant_correlations = so_correlations[abs(so_correlations) > 0.3]
print(f"\nCorrela√ß√µes significativas (|r| > 0.3):")
for feature, corr in significant_correlations.items():
    strength = "Forte" if abs(corr) > 0.7 else "Moderada" if abs(corr) > 0.5 else "Fraca"
    direction = "Positiva" if corr > 0 else "Negativa"
    print(f"  {feature:15} : {corr:8.4f} ({strength} {direction})")

# ============================================================================
# 2. REMO√á√ÉO DE FEATURES PROBLEM√ÅTICAS
# ============================================================================

def remove_problematic_features(df):
    """
    Remove features com correla√ß√µes negativas/irrelevantes
    """
    print("\nüóëÔ∏è REMOVENDO FEATURES PROBLEM√ÅTICAS")
    print("-" * 50)
    
    # Features para remover (baseado na an√°lise de correla√ß√£o)
    features_to_remove = [
        'ERA',      # -0.0911 (negativa fraca)
        'FIP',      # -0.1407 (negativa, pode confundir modelo)
        'Home',     # -0.0114 (irrelevante)
        'DR',       # -0.0659 (negativa, provavelmente ru√≠do)
        'aLI',      # -0.0690 (negativa, situa√ß√µes de press√£o podem reduzir SO)
        'H',        # 0.0005 (muito fraca + pode ser derivada de outras)
        'BB',       # -0.0529 (fraca negativa)
        'Season'    # 0.1455 (apenas tend√™ncia temporal, n√£o preditiva)
    ]
    
    # Verificar quais existem no DataFrame
    existing_features = [f for f in features_to_remove if f in df.columns]
    missing_features = [f for f in features_to_remove if f not in df.columns]
    
    print(f"Features a remover: {existing_features}")
    
    # Remover as features
    df = df.drop(columns=existing_features)
    
    return df

df = remove_problematic_features(df)

print(df.columns)

df.to_csv('../pitchers_data_with_opp_so_cleaned.csv', index=False)