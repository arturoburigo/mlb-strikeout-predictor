{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando arquivo mais recente: betting_data_2025-03-30.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Data Loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_data():\n",
    "    # Find the most recent betting data file\n",
    "    betting_files = glob.glob('betting_data_*.csv')\n",
    "    \n",
    "    if not betting_files:\n",
    "        # Fallback to the default name if no date-specific files found\n",
    "        betting_file = 'betting_data.csv'\n",
    "        print(f\"Usando arquivo padrão: {betting_file}\")\n",
    "    else:\n",
    "        # Sort files by date (assuming format betting_data_YYYY-MM-DD.csv)\n",
    "        betting_files.sort(key=lambda x: datetime.strptime(x.split('_')[2].split('.')[0], '%Y-%m-%d'), reverse=True)\n",
    "        betting_file = betting_files[0]\n",
    "        print(f\"Usando arquivo mais recente: {betting_file}\")\n",
    "    \n",
    "    # Load all datasets\n",
    "    k_percentage_df = pd.read_csv('team_strikeout_percentage.csv')\n",
    "    pitcher_data = pd.read_csv('pitchers_data.csv')\n",
    "    betting_data = pd.read_csv(betting_file)\n",
    "    \n",
    "    # Merge and preprocess data\n",
    "    pitcher_data = pitcher_data.merge(\n",
    "        betting_data[['Name_abbreviation', 'Team']], \n",
    "        left_on='Pitcher', \n",
    "        right_on='Name_abbreviation', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Feature engineering\n",
    "    pitcher_data['SO_per_IP'] = pitcher_data['SO'] / pitcher_data['IP']\n",
    "    pitcher_data['BB_per_IP'] = pitcher_data['BB'] / pitcher_data['IP']\n",
    "    pitcher_data['K-BB%'] = pitcher_data['SO_per_IP'] - pitcher_data['BB_per_IP']\n",
    "    \n",
    "    # Merge with team stats\n",
    "    pitcher_data = pitcher_data.merge(k_percentage_df, on='Team', how='left')\n",
    "    pitcher_data.rename(columns={'%K': 'Team_K%'}, inplace=True)\n",
    "    pitcher_data = pitcher_data.merge(\n",
    "        k_percentage_df.rename(columns={'%K': 'Opp_K%'}), \n",
    "        left_on='Opp', right_on='Team', how='left'\n",
    "    )\n",
    "    \n",
    "    # Handle missing values\n",
    "    pitcher_data.fillna({\n",
    "        'SO_per_IP': pitcher_data['SO_per_IP'].mean(),\n",
    "        'BB_per_IP': pitcher_data['BB_per_IP'].mean(),\n",
    "        'Team_K%': pitcher_data['Team_K%'].mean(),\n",
    "        'Opp_K%': pitcher_data['Opp_K%'].mean()\n",
    "    }, inplace=True)\n",
    "    \n",
    "    return pitcher_data, k_percentage_df, betting_file\n",
    "\n",
    "pitchers_df, k_percentage_df, betting_file_used = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Performance Calculation Function\n",
    "def calculate_weighted_performance(pitcher_data, current_season, last_season=None):\n",
    "    current_season_data = pitcher_data[pitcher_data['Season'] == current_season]\n",
    "    last_5_games = current_season_data.tail(5)\n",
    "    last_10_games = current_season_data.tail(10)\n",
    "    \n",
    "    # Calculate rolling averages\n",
    "    current_season_data['SO_rolling_5'] = current_season_data['SO'].rolling(5).mean()\n",
    "    current_season_data['SO_rolling_10'] = current_season_data['SO'].rolling(10).mean()\n",
    "    \n",
    "    # Calculate home/away splits\n",
    "    home_stats = current_season_data[current_season_data['Home'] == 1.0].mean(numeric_only=True)\n",
    "    away_stats = current_season_data[current_season_data['Home'] == 0.0].mean(numeric_only=True)\n",
    "\n",
    "    if last_season is not None:\n",
    "        last_season_data = pitcher_data[pitcher_data['Season'] == last_season]\n",
    "        weight_current_season = 0.40\n",
    "        weight_last_5_games = 0.25\n",
    "        weight_last_10_games = 0.15\n",
    "        weight_last_season = 0.20\n",
    "    else:\n",
    "        last_season_data = pd.DataFrame()\n",
    "        weight_current_season = 0.50\n",
    "        weight_last_5_games = 0.30\n",
    "        weight_last_10_games = 0.20\n",
    "        weight_last_season = 0.0\n",
    "\n",
    "    metrics = ['IP', 'H', 'BB', 'ERA', 'FIP', 'SO', 'SO_rolling_5', 'SO_rolling_10']\n",
    "    weighted_values = {}\n",
    "\n",
    "    for metric in metrics:\n",
    "        current_mean = current_season_data[metric].mean() if not current_season_data.empty else 0\n",
    "        last_5_mean = last_5_games[metric].mean() if not last_5_games.empty else 0\n",
    "        last_10_mean = last_10_games[metric].mean() if not last_10_games.empty else 0\n",
    "        last_season_mean = last_season_data[metric].mean() if not last_season_data.empty else 0\n",
    "\n",
    "        weighted_values[metric] = (\n",
    "            weight_current_season * current_mean +\n",
    "            weight_last_5_games * last_5_mean +\n",
    "            weight_last_10_games * last_10_mean +\n",
    "            weight_last_season * last_season_mean\n",
    "        )\n",
    "    \n",
    "    # Add home/away splits\n",
    "    weighted_values['Home_IP'] = home_stats.get('IP', 0)\n",
    "    weighted_values['Away_IP'] = away_stats.get('IP', 0)\n",
    "    weighted_values['Home_SO'] = home_stats.get('SO', 0)\n",
    "    weighted_values['Away_SO'] = away_stats.get('SO', 0)\n",
    "    weighted_values['Home'] = current_season_data['Home'].mean()\n",
    "    \n",
    "    return weighted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest    | CV R2: 0.4990 | Test R2: 0.7676 | Test MAE: 0.6934\n",
      "XGBoost         | CV R2: -0.4037 | Test R2: 0.5750 | Test MAE: 0.7233\n",
      "LightGBM        | CV R2: -2.3210 | Test R2: 0.9730 | Test MAE: 0.2524\n",
      "GradientBoosting | CV R2: -0.5121 | Test R2: 0.7739 | Test MAE: 0.5503\n",
      "\n",
      "Best model: RandomForest with R2 score: 0.4990\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightgbm\")\n",
    "\n",
    "def train_model(pitchers_df, k_percentage_df):\n",
    "    # Calculate weighted performance for each pitcher\n",
    "    weighted_pitcher_data = []\n",
    "    pitchers_df = pitchers_df[(pitchers_df['Season'] == 2023) | (pitchers_df['Season'] == 2024)]\n",
    "\n",
    "    for pitcher in pitchers_df['Pitcher'].unique():\n",
    "        pitcher_data = pitchers_df[pitchers_df['Pitcher'] == pitcher].copy()\n",
    "        \n",
    "        if 'SO' not in pitcher_data.columns:\n",
    "            pitcher_data['SO'] = 0\n",
    "            \n",
    "        pitcher_data = pitcher_data.sort_values('Season')\n",
    "        pitcher_data['SO_rolling_5'] = pitcher_data['SO'].rolling(5, min_periods=1).mean()\n",
    "        pitcher_data['SO_rolling_10'] = pitcher_data['SO'].rolling(10, min_periods=1).mean()\n",
    "        \n",
    "        pitcher_data['Home_IP'] = pitcher_data[pitcher_data['Home'] == 1.0]['IP'].mean()\n",
    "        pitcher_data['Away_IP'] = pitcher_data[pitcher_data['Home'] == 0.0]['IP'].mean()\n",
    "        pitcher_data['Home_SO'] = pitcher_data[pitcher_data['Home'] == 1.0]['SO'].mean()\n",
    "        pitcher_data['Away_SO'] = pitcher_data[pitcher_data['Home'] == 0.0]['SO'].mean()\n",
    "        \n",
    "        performance = calculate_weighted_performance(pitcher_data, current_season=2024, last_season=2023)\n",
    "        performance['Pitcher'] = pitcher\n",
    "        performance['Opp_K%'] = pitcher_data['Opp_K%'].iloc[0] if not pitcher_data.empty else k_percentage_df['%K'].mean()\n",
    "        performance['Team_K%'] = pitcher_data['Team_K%'].iloc[0] if not pitcher_data.empty else k_percentage_df['%K'].mean()\n",
    "        weighted_pitcher_data.append(performance)\n",
    "\n",
    "    weighted_df = pd.DataFrame(weighted_pitcher_data)\n",
    "    \n",
    "    weighted_df['IP'] = weighted_df['IP'].replace(0, 1)\n",
    "    weighted_df['SO_per_IP'] = weighted_df['SO'] / weighted_df['IP']\n",
    "    weighted_df['BB_per_IP'] = weighted_df['BB'] / weighted_df['IP']\n",
    "    weighted_df['K-BB%'] = weighted_df['SO_per_IP'] - weighted_df['BB_per_IP']\n",
    "    \n",
    "    required_features = [\n",
    "        'IP', 'H', 'BB', 'ERA', 'FIP', 'SO_per_IP', 'BB_per_IP', 'K-BB%', \n",
    "        'Opp_K%', 'Team_K%', 'Home', 'SO_rolling_5', 'SO_rolling_10',\n",
    "        'Home_IP', 'Away_IP', 'Home_SO', 'Away_SO'\n",
    "    ]\n",
    "    \n",
    "    for feature in required_features:\n",
    "        if feature not in weighted_df.columns:\n",
    "            weighted_df[feature] = 0\n",
    "            print(f\"Warning: Initialized missing feature {feature} with zeros\")\n",
    "    \n",
    "    X = weighted_df[required_features].fillna(0)\n",
    "    y = weighted_df['SO']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    models = {\n",
    "        'RandomForest': RandomForestRegressor(random_state=42),\n",
    "        'XGBoost': XGBRegressor(random_state=42),\n",
    "        'LightGBM': LGBMRegressor(random_state=42, num_leaves=31, min_data_in_leaf=1, max_depth=-1, verbose=-1),\n",
    "        'GradientBoosting': GradientBoostingRegressor(random_state=42)\n",
    "    }\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "    best_model_name = \"\"\n",
    "    results = {}\n",
    "\n",
    "    for name, model in models.items():\n",
    "        pipeline = make_pipeline(RobustScaler(), model)\n",
    "        \n",
    "        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "        avg_score = np.mean(scores)\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        test_mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        results[name] = {\n",
    "            'CV_R2': avg_score,\n",
    "            'Test_R2': test_r2,\n",
    "            'Test_MAE': test_mae\n",
    "        }\n",
    "        \n",
    "        print(f\"{name:15} | CV R2: {avg_score:.4f} | Test R2: {test_r2:.4f} | Test MAE: {test_mae:.4f}\")\n",
    "        \n",
    "        if avg_score > best_score:\n",
    "            best_score = avg_score\n",
    "            best_model = pipeline\n",
    "            best_model_name = name\n",
    "\n",
    "    print(f\"\\nBest model: {best_model_name} with R2 score: {best_score:.4f}\")\n",
    "    return best_model, results\n",
    "\n",
    "model, model_results = train_model(pitchers_df, k_percentage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_strikeouts_with_confidence(model, pitchers_df, k_percentage_df, pitcher_name, opponent_team, strikeout_line):\n",
    "    \"\"\"\n",
    "    Make prediction with confidence metrics for a pitcher vs opponent.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ML pipeline\n",
    "        pitchers_df: Pitchers historical data\n",
    "        k_percentage_df: Team strikeout percentages\n",
    "        pitcher_name: Pitcher abbreviation\n",
    "        opponent_team: Opponent team abbreviation\n",
    "        strikeout_line: Betting line for strikeouts\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with prediction, recommendation and confidence metrics\n",
    "        or None if prediction couldn't be made\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid SettingWithCopyWarning\n",
    "    pitcher_data = pitchers_df[pitchers_df['Pitcher'] == pitcher_name].copy()\n",
    "    \n",
    "    if pitcher_data.empty:\n",
    "        print(f\"No data found for pitcher: {pitcher_name}\")\n",
    "        return None\n",
    "\n",
    "    # Ensure we have required columns for rolling calculations\n",
    "    required_columns = ['Season', 'SO', 'IP', 'Home']\n",
    "    for col in required_columns:\n",
    "        if col not in pitcher_data.columns:\n",
    "            pitcher_data[col] = 0  # Initialize with default value\n",
    "            \n",
    "    # Calculate rolling features with proper sorting\n",
    "    pitcher_data = pitcher_data.sort_values('Season')\n",
    "    pitcher_data['SO_rolling_5'] = pitcher_data['SO'].rolling(5, min_periods=1).mean()\n",
    "    pitcher_data['SO_rolling_10'] = pitcher_data['SO'].rolling(10, min_periods=1).mean()\n",
    "    \n",
    "    # Calculate home/away splits\n",
    "    pitcher_data['Home_IP'] = pitcher_data[pitcher_data['Home'] == 1.0]['IP'].mean()\n",
    "    pitcher_data['Away_IP'] = pitcher_data[pitcher_data['Home'] == 0.0]['IP'].mean()\n",
    "    pitcher_data['Home_SO'] = pitcher_data[pitcher_data['Home'] == 1.0]['SO'].mean()\n",
    "    pitcher_data['Away_SO'] = pitcher_data[pitcher_data['Home'] == 0.0]['SO'].mean()\n",
    "\n",
    "    # Get opponent strikeout rate\n",
    "    opponent_k = k_percentage_df.loc[k_percentage_df['Team'] == opponent_team, '%K'].mean()\n",
    "    if np.isnan(opponent_k):\n",
    "        opponent_k = k_percentage_df['%K'].mean()  # Fallback to league average\n",
    "    \n",
    "    # Calculate weighted performance metrics\n",
    "    performance = calculate_weighted_performance(\n",
    "        pitcher_data=pitcher_data,\n",
    "        current_season=2024,\n",
    "        last_season=2023 if not pitcher_data[pitcher_data['Season'] == 2023].empty else None\n",
    "    )\n",
    "    \n",
    "    # Prepare features DataFrame\n",
    "    features = pd.DataFrame([performance])\n",
    "    \n",
    "    # Add derived features with safety checks\n",
    "    features['IP'] = features['IP'].replace(0, 1)  # Avoid division by zero\n",
    "    features['SO_per_IP'] = features['SO'] / features['IP']\n",
    "    features['BB_per_IP'] = features['BB'] / features['IP']\n",
    "    features['K-BB%'] = features['SO_per_IP'] - features['BB_per_IP']\n",
    "    features['Opp_K%'] = opponent_k\n",
    "    features['Team_K%'] = pitcher_data['Team_K%'].iloc[0] if not pitcher_data.empty else k_percentage_df['%K'].mean()\n",
    "    \n",
    "    # Define and validate all required features\n",
    "    model_features = [\n",
    "        'IP', 'H', 'BB', 'ERA', 'FIP', 'SO_per_IP', 'BB_per_IP', 'K-BB%', \n",
    "        'Opp_K%', 'Team_K%', 'Home', 'SO_rolling_5', 'SO_rolling_10',\n",
    "        'Home_IP', 'Away_IP', 'Home_SO', 'Away_SO'\n",
    "    ]\n",
    "    \n",
    "    # Ensure all features exist in the DataFrame\n",
    "    for feature in model_features:\n",
    "        if feature not in features.columns:\n",
    "            features[feature] = 0  # Initialize missing features with 0\n",
    "            print(f\"Warning: Initialized missing feature {feature} with zeros\")\n",
    "    \n",
    "    input_features = features[model_features].fillna(0)\n",
    "    \n",
    "    try:\n",
    "        # Make prediction\n",
    "        predicted_strikeouts = model.predict(input_features)[0]\n",
    "        \n",
    "        # Calculate confidence metrics\n",
    "        if hasattr(model, 'named_steps') and 'randomforestregressor' in model.named_steps:\n",
    "            # For RandomForest - use tree variance\n",
    "            predictions = [tree.predict(input_features) for tree in \n",
    "                         model.named_steps.randomforestregressor.estimators_]\n",
    "            std_dev = np.std(predictions)\n",
    "            confidence = max(0, min(1 - (std_dev / 3), 1))\n",
    "        else:\n",
    "            # For other models - use simple confidence based on line proximity\n",
    "            std_dev = 0\n",
    "            confidence = 0.8 - (abs(predicted_strikeouts - strikeout_line) / 10)\n",
    "            confidence = max(0, min(confidence, 1))\n",
    "        \n",
    "        # Determine recommendation\n",
    "        recommended_side = \"Over\" if predicted_strikeouts > strikeout_line else \"Under\"\n",
    "        \n",
    "        return {\n",
    "            'predicted_value': float(predicted_strikeouts),\n",
    "            'recommended_side': recommended_side,\n",
    "            'confidence_percentage': float(confidence * 100),\n",
    "            'std_dev': float(std_dev)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Prediction failed for {pitcher_name}: {str(e)}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_betting_data(model, pitchers_df, k_percentage_df, betting_data_path, output_dir=None):\n",
    "    \"\"\"\n",
    "    Process betting data and add predictions using the trained model.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained ML pipeline\n",
    "        pitchers_df: Pitchers historical data\n",
    "        k_percentage_df: Team strikeout percentages\n",
    "        betting_data_path: Path to betting data CSV\n",
    "        output_dir: Directory to save the output file (defaults to current directory)\n",
    "        \n",
    "    Returns:\n",
    "        Updated betting DataFrame with predictions (only rows with valid predictions and selected columns)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    \n",
    "    # Load betting data\n",
    "    betting_data = pd.read_csv(betting_data_path)\n",
    "    \n",
    "    # Initialize prediction columns\n",
    "    betting_data['ML Strikeout Line'] = (betting_data['Over Line'] + betting_data['Under Line']) / 2\n",
    "    betting_data['ML Predict Value'] = np.nan\n",
    "    betting_data['ML Recommend Side'] = np.nan\n",
    "    betting_data['ML Confidence Percentage'] = np.nan\n",
    "    betting_data['Pitcher 2023'] = False\n",
    "    \n",
    "    def has_2023_data(pitcher_name):\n",
    "        \"\"\"Check if pitcher has 2023 data available.\"\"\"\n",
    "        return not pitchers_df[(pitchers_df['Pitcher'] == pitcher_name) & \n",
    "                             (pitchers_df['Season'] == 2023)].empty\n",
    "    \n",
    "    for index, row in betting_data.iterrows():\n",
    "        pitcher_name = row['Name_abbreviation']\n",
    "        opponent_team = row['Opponent']\n",
    "        strikeout_line = row['ML Strikeout Line']\n",
    "        \n",
    "        pitcher_2023 = has_2023_data(pitcher_name)\n",
    "        betting_data.at[index, 'Pitcher 2023'] = pitcher_2023\n",
    "        \n",
    "        # Make prediction\n",
    "        result = predict_strikeouts_with_confidence(\n",
    "            model=model,\n",
    "            pitchers_df=pitchers_df,\n",
    "            k_percentage_df=k_percentage_df,\n",
    "            pitcher_name=pitcher_name,\n",
    "            opponent_team=opponent_team,\n",
    "            strikeout_line=strikeout_line\n",
    "        )\n",
    "        \n",
    "        if result:\n",
    "            betting_data.at[index, 'ML Predict Value'] = result['predicted_value']\n",
    "            betting_data.at[index, 'ML Recommend Side'] = result['recommended_side']\n",
    "            betting_data.at[index, 'ML Confidence Percentage'] = result['confidence_percentage']\n",
    "            \n",
    "            # Print progress\n",
    "            print(f\"{pitcher_name} vs {opponent_team}: \"\n",
    "                  f\"Line {strikeout_line:.1f} → Pred {result['predicted_value']:.1f} \"\n",
    "                  f\"({result['recommended_side']}, {result['confidence_percentage']:.0f}%)\")\n",
    "        else:\n",
    "            print(f\"⚠️ No prediction for {pitcher_name} vs {opponent_team} - missing data\")\n",
    "    \n",
    "    # FILTRAR APENAS LINHAS COM PREVISÕES VÁLIDAS\n",
    "    filtered_data = betting_data.dropna(subset=['ML Predict Value'])\n",
    "    \n",
    "    # REMOVER COLUNAS INDESEJADAS\n",
    "    columns_to_drop = ['Opponent', 'Home Team', 'Away Team', 'Probability', 'Bet Rating']\n",
    "    columns_to_keep = [col for col in filtered_data.columns if col not in columns_to_drop]\n",
    "    filtered_data = filtered_data[columns_to_keep]\n",
    "    \n",
    "    # Extract date from input filename or use current date\n",
    "    import re\n",
    "    date_match = re.search(r'xPbetting_data_(\\d{4}-\\d{2}-\\d{2})\\.csv', betting_data_path)\n",
    "    if date_match:\n",
    "        file_date = date_match.group(1)\n",
    "    else:\n",
    "        file_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Create output filename\n",
    "    output_filename = f\"betting_data_predicted_{file_date}.csv\"\n",
    "    \n",
    "    # Set output path\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "    else:\n",
    "        output_path = output_filename\n",
    "    \n",
    "    # Save the filtered data\n",
    "    filtered_data.to_csv(output_path, index=False)\n",
    "    print(f\"\\nSaved predictions to {output_path}\")\n",
    "    print(f\"Original rows: {len(betting_data)} | Filtered rows with predictions: {len(filtered_data)}\")\n",
    "    print(f\"Columns kept: {len(columns_to_keep)} | Columns removed: {len(columns_to_drop)}\")\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data found for pitcher: degroja\n",
      "⚠️ No prediction for degroja vs nan - missing data\n",
      "oberba vs nan: Line 4.8 → Pred 5.6 (Over, 77%)\n",
      "bibeeta vs nan: Line 4.5 → Pred 5.9 (Over, 75%)\n",
      "meyerma vs nan: Line 4.0 → Pred 3.9 (Under, 75%)\n",
      "nolaaa vs nan: Line 5.2 → Pred 5.7 (Over, 77%)\n",
      "bradlta vs nan: Line 6.5 → Pred 6.0 (Under, 75%)\n",
      "heanean vs nan: Line 4.2 → Pred 4.8 (Over, 75%)\n",
      "No data found for pitcher: suganto\n",
      "⚠️ No prediction for suganto vs nan - missing data\n",
      "kochaja vs nan: Line 2.8 → Pred 3.5 (Over, 77%)\n",
      "pivetni vs nan: Line 5.5 → Pred 5.7 (Over, 76%)\n",
      "boydma vs nan: Line 4.5 → Pred 5.5 (Over, 74%)\n",
      "searsjp vs nan: Line 4.2 → Pred 3.9 (Under, 75%)\n",
      "woobr vs nan: Line 5.5 → Pred 4.4 (Under, 77%)\n",
      "pallaan vs nan: Line 4.0 → Pred 2.8 (Under, 75%)\n",
      "martida vs nan: Line 4.2 → Pred 4.1 (Under, 75%)\n",
      "No data found for pitcher: rodried\n",
      "⚠️ No prediction for rodried vs nan - missing data\n",
      "stromma vs nan: Line 3.8 → Pred 4.0 (Over, 75%)\n",
      "wachami vs nan: Line 4.5 → Pred 4.8 (Over, 75%)\n",
      "civalaa vs nan: Line 4.5 → Pred 4.9 (Over, 75%)\n",
      "bassich vs nan: Line 5.0 → Pred 5.0 (Under, 75%)\n",
      "martini vs nan: Line 4.5 → Pred 2.7 (Under, 77%)\n",
      "No data found for pitcher: fittsri\n",
      "⚠️ No prediction for fittsri vs nan - missing data\n",
      "parkemi vs nan: Line 4.5 → Pred 4.7 (Over, 75%)\n",
      "feltnry vs nan: Line 4.5 → Pred 4.5 (Under, 75%)\n",
      "\n",
      "Saved predictions to predictions/betting_data_predicted_2025-03-30.csv\n",
      "Original rows: 24 | Filtered rows with predictions: 20\n",
      "Columns kept: 17 | Columns removed: 5\n"
     ]
    }
   ],
   "source": [
    "# Usar o mesmo arquivo que foi carregado inicialmente\n",
    "results_df = process_betting_data(\n",
    "    model=model,\n",
    "    pitchers_df=pitchers_df,\n",
    "    k_percentage_df=k_percentage_df,\n",
    "    betting_data_path=betting_file_used,  # usando a variável da célula 1\n",
    "    output_dir='predictions'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
